{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "obs_space = len(env.observation_space.high)\n",
    "buckets = (20, 20, 20, 20)\n",
    "LEARNING_RATE = 0.1\n",
    "EPISODES = 99000\n",
    "RENDER_RATE = 500\n",
    "DISCOUNT = 0.95\n",
    "MAX_FRAMES = 500\n",
    "epsilon = 1\n",
    "START_EPSILON_DECAYING = 1\n",
    "END_EPSILON_DECAYING = EPISODES//2\n",
    "epsilon_decay_value = epsilon/(END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
    "act_space = env.action_space.n\n",
    "bucket_size = env.observation_space.high/buckets - env.observation_space.low/buckets\n",
    "q_table = np.random.randint(low=0, high=10, size=(buckets + (act_space,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_no(state):\n",
    "    bucket = state/bucket_size - env.observation_space.low/bucket_size\n",
    "    return tuple(bucket.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action(state):\n",
    "    return np.argmax(q_table[bucket_no(state)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    frame_min = 50\n",
    "    epsilon = 1\n",
    "    for episode in range(EPISODES):\n",
    "        prev_state = env.reset()\n",
    "        step = next_action(prev_state)\n",
    "        curr_state, _, done, info = env.step(step)\n",
    "        render = False\n",
    "        if episode % RENDER_RATE == 0:\n",
    "            render = True\n",
    "        for frame in range(MAX_FRAMES):\n",
    "            if render:\n",
    "                env.render()\n",
    "            qt_current = q_table[bucket_no(prev_state) + (step,)]\n",
    "            max_qt_poss = np.max(q_table[bucket_no(curr_state)])\n",
    "            new_q = (1 - LEARNING_RATE) * qt_current + LEARNING_RATE * (frame + DISCOUNT * max_qt_poss)\n",
    "            q_table[bucket_no(prev_state) + (step,)] = new_q\n",
    "            if np.random.random() > epsilon:\n",
    "                step = next_action(curr_state)\n",
    "            else:\n",
    "                step = np.random.randint(0, env.action_space.n)\n",
    "            prev_state = curr_state\n",
    "            new_state, _, done, info = env.step(step)\n",
    "            if done:\n",
    "                if render:\n",
    "                    print('episode = %d' % episode)\n",
    "                    print(frame)\n",
    "                break\n",
    "        if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\n",
    "            epsilon -= epsilon_decay_value\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode = 0\n",
      "33\n",
      "episode = 500\n",
      "26\n",
      "episode = 1000\n",
      "17\n",
      "episode = 1500\n",
      "15\n",
      "episode = 2000\n",
      "12\n",
      "episode = 2500\n",
      "25\n",
      "episode = 3000\n",
      "11\n",
      "episode = 3500\n",
      "13\n",
      "episode = 4000\n",
      "31\n",
      "episode = 4500\n",
      "15\n",
      "episode = 5000\n",
      "47\n",
      "episode = 5500\n",
      "39\n",
      "episode = 6000\n",
      "16\n",
      "episode = 6500\n",
      "8\n",
      "episode = 7000\n",
      "17\n",
      "episode = 7500\n",
      "14\n",
      "episode = 8000\n",
      "35\n",
      "episode = 8500\n",
      "51\n",
      "episode = 9000\n",
      "31\n",
      "episode = 9500\n",
      "20\n",
      "episode = 10000\n",
      "40\n",
      "episode = 10500\n",
      "25\n",
      "episode = 11000\n",
      "8\n",
      "episode = 11500\n",
      "13\n",
      "episode = 12000\n",
      "22\n",
      "episode = 12500\n",
      "20\n",
      "episode = 13000\n",
      "13\n",
      "episode = 13500\n",
      "29\n",
      "episode = 14000\n",
      "12\n",
      "episode = 14500\n",
      "25\n",
      "episode = 15000\n",
      "23\n",
      "episode = 15500\n",
      "10\n",
      "episode = 16000\n",
      "8\n",
      "episode = 16500\n",
      "23\n",
      "episode = 17000\n",
      "38\n",
      "episode = 17500\n",
      "35\n",
      "episode = 18000\n",
      "27\n",
      "episode = 18500\n",
      "25\n",
      "episode = 19000\n",
      "12\n",
      "episode = 19500\n",
      "9\n",
      "episode = 20000\n",
      "12\n",
      "episode = 20500\n",
      "7\n",
      "episode = 21000\n",
      "13\n",
      "episode = 21500\n",
      "14\n",
      "episode = 22000\n",
      "11\n",
      "episode = 22500\n",
      "15\n",
      "episode = 23000\n",
      "24\n",
      "episode = 23500\n",
      "35\n",
      "episode = 24000\n",
      "19\n",
      "episode = 24500\n",
      "28\n",
      "episode = 25000\n",
      "28\n",
      "episode = 25500\n",
      "12\n",
      "episode = 26000\n",
      "32\n",
      "episode = 26500\n",
      "22\n",
      "episode = 27000\n",
      "18\n",
      "episode = 27500\n",
      "15\n",
      "episode = 28000\n",
      "14\n",
      "episode = 28500\n",
      "10\n",
      "episode = 29000\n",
      "10\n",
      "episode = 29500\n",
      "12\n",
      "episode = 30000\n",
      "13\n",
      "episode = 30500\n",
      "7\n",
      "episode = 31000\n",
      "8\n",
      "episode = 31500\n",
      "13\n",
      "episode = 32000\n",
      "13\n",
      "episode = 32500\n",
      "12\n",
      "episode = 33000\n",
      "15\n",
      "episode = 33500\n",
      "7\n",
      "episode = 34000\n",
      "12\n",
      "episode = 34500\n",
      "9\n",
      "episode = 35000\n",
      "10\n",
      "episode = 35500\n",
      "11\n",
      "episode = 36000\n",
      "15\n",
      "episode = 36500\n",
      "7\n",
      "episode = 37000\n",
      "10\n",
      "episode = 37500\n",
      "10\n",
      "episode = 38000\n",
      "6\n",
      "episode = 38500\n",
      "10\n",
      "episode = 39000\n",
      "7\n",
      "episode = 39500\n",
      "11\n",
      "episode = 40000\n",
      "12\n",
      "episode = 40500\n",
      "17\n",
      "episode = 41000\n",
      "27\n",
      "episode = 41500\n",
      "9\n",
      "episode = 42000\n",
      "7\n",
      "episode = 42500\n",
      "9\n",
      "episode = 43000\n",
      "10\n",
      "episode = 43500\n",
      "7\n",
      "episode = 44000\n",
      "8\n",
      "episode = 44500\n",
      "8\n",
      "episode = 45000\n",
      "9\n",
      "episode = 45500\n",
      "7\n",
      "episode = 46000\n",
      "7\n",
      "episode = 46500\n",
      "7\n",
      "episode = 47000\n",
      "7\n",
      "episode = 47500\n",
      "8\n",
      "episode = 48000\n",
      "8\n",
      "episode = 48500\n",
      "8\n",
      "episode = 49000\n",
      "7\n",
      "episode = 49500\n",
      "6\n",
      "episode = 50000\n",
      "8\n",
      "episode = 50500\n",
      "6\n",
      "episode = 51000\n",
      "7\n",
      "episode = 51500\n",
      "8\n",
      "episode = 52000\n",
      "6\n",
      "episode = 52500\n",
      "7\n",
      "episode = 53000\n",
      "8\n",
      "episode = 53500\n",
      "8\n",
      "episode = 54000\n",
      "7\n",
      "episode = 54500\n",
      "7\n",
      "episode = 55000\n",
      "6\n",
      "episode = 55500\n",
      "8\n",
      "episode = 56000\n",
      "7\n",
      "episode = 56500\n",
      "6\n",
      "episode = 57000\n",
      "8\n",
      "episode = 57500\n",
      "8\n",
      "episode = 58000\n",
      "8\n",
      "episode = 58500\n",
      "7\n",
      "episode = 59000\n",
      "8\n",
      "episode = 59500\n",
      "7\n",
      "episode = 60000\n",
      "7\n",
      "episode = 60500\n",
      "8\n",
      "episode = 61000\n",
      "7\n",
      "episode = 61500\n",
      "8\n",
      "episode = 62000\n",
      "6\n",
      "episode = 62500\n",
      "8\n",
      "episode = 63000\n",
      "7\n",
      "episode = 63500\n",
      "6\n",
      "episode = 64000\n",
      "7\n",
      "episode = 64500\n",
      "8\n",
      "episode = 65000\n",
      "8\n",
      "episode = 65500\n",
      "8\n",
      "episode = 66000\n",
      "8\n",
      "episode = 66500\n",
      "8\n",
      "episode = 67000\n",
      "7\n",
      "episode = 67500\n",
      "7\n",
      "episode = 68000\n",
      "6\n",
      "episode = 68500\n",
      "8\n",
      "episode = 69000\n",
      "7\n",
      "episode = 69500\n",
      "8\n",
      "episode = 70000\n",
      "6\n",
      "episode = 70500\n",
      "7\n",
      "episode = 71000\n",
      "8\n",
      "episode = 71500\n",
      "7\n",
      "episode = 72000\n",
      "8\n",
      "episode = 72500\n",
      "8\n",
      "episode = 73000\n",
      "6\n",
      "episode = 73500\n",
      "7\n",
      "episode = 74000\n",
      "7\n",
      "episode = 74500\n",
      "7\n",
      "episode = 75000\n",
      "7\n",
      "episode = 75500\n",
      "7\n",
      "episode = 76000\n",
      "8\n",
      "episode = 76500\n",
      "6\n",
      "episode = 77000\n",
      "6\n",
      "episode = 77500\n",
      "7\n",
      "episode = 78000\n",
      "9\n",
      "episode = 78500\n",
      "7\n",
      "episode = 79000\n",
      "7\n",
      "episode = 79500\n",
      "7\n",
      "episode = 80000\n",
      "9\n",
      "episode = 80500\n",
      "8\n",
      "episode = 81000\n",
      "9\n",
      "episode = 81500\n",
      "6\n",
      "episode = 82000\n",
      "8\n",
      "episode = 82500\n",
      "8\n",
      "episode = 83000\n",
      "8\n",
      "episode = 83500\n",
      "8\n",
      "episode = 84000\n",
      "8\n",
      "episode = 84500\n",
      "7\n",
      "episode = 85000\n",
      "7\n",
      "episode = 85500\n",
      "8\n",
      "episode = 86000\n",
      "8\n",
      "episode = 86500\n",
      "8\n",
      "episode = 87000\n",
      "7\n",
      "episode = 87500\n",
      "6\n",
      "episode = 88000\n",
      "7\n",
      "episode = 88500\n",
      "8\n",
      "episode = 89000\n",
      "8\n",
      "episode = 89500\n",
      "8\n",
      "episode = 90000\n",
      "6\n",
      "episode = 90500\n",
      "7\n",
      "episode = 91000\n",
      "6\n",
      "episode = 91500\n",
      "7\n",
      "episode = 92000\n",
      "8\n",
      "episode = 92500\n",
      "8\n",
      "episode = 93000\n",
      "8\n",
      "episode = 93500\n",
      "8\n",
      "episode = 94000\n",
      "7\n",
      "episode = 94500\n",
      "9\n",
      "episode = 95000\n",
      "8\n",
      "episode = 95500\n",
      "7\n",
      "episode = 96000\n",
      "7\n",
      "episode = 96500\n",
      "8\n",
      "episode = 97000\n",
      "7\n",
      "episode = 97500\n",
      "9\n",
      "episode = 98000\n",
      "8\n",
      "episode = 98500\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "frame=23\n",
      "avg_frames=23.0\n",
      "1000\n",
      "frame=13\n",
      "avg_frames=21.865134865134866\n",
      "2000\n",
      "frame=27\n",
      "avg_frames=21.55322338830585\n",
      "3000\n",
      "frame=24\n",
      "avg_frames=21.60746417860713\n",
      "4000\n",
      "frame=17\n",
      "avg_frames=21.640339915021244\n",
      "5000\n",
      "frame=20\n",
      "avg_frames=21.66526694661068\n",
      "6000\n",
      "frame=10\n",
      "avg_frames=21.60573237793701\n",
      "7000\n",
      "frame=22\n",
      "avg_frames=21.48093129552921\n",
      "8000\n",
      "frame=9\n",
      "avg_frames=21.41682289713786\n",
      "9000\n",
      "frame=20\n",
      "avg_frames=21.397733585157205\n",
      "10000\n",
      "frame=17\n",
      "avg_frames=21.364163583641634\n",
      "11000\n",
      "frame=10\n",
      "avg_frames=21.264521407144805\n",
      "12000\n",
      "frame=20\n",
      "avg_frames=21.209899175068745\n",
      "13000\n",
      "frame=19\n",
      "avg_frames=21.24390431505269\n",
      "14000\n",
      "frame=36\n",
      "avg_frames=21.210127848010856\n",
      "15000\n",
      "frame=17\n",
      "avg_frames=21.18552096526898\n",
      "16000\n",
      "frame=12\n",
      "avg_frames=21.200362477345166\n",
      "17000\n",
      "frame=18\n",
      "avg_frames=21.21698723604494\n",
      "18000\n",
      "frame=16\n",
      "avg_frames=21.23404255319149\n",
      "19000\n",
      "frame=38\n",
      "avg_frames=21.235408662701964\n",
      "20000\n",
      "frame=12\n",
      "avg_frames=21.22938853057347\n",
      "21000\n",
      "frame=13\n",
      "avg_frames=21.223608399600018\n",
      "22000\n",
      "frame=19\n",
      "avg_frames=21.24448888686878\n",
      "23000\n",
      "frame=21\n",
      "avg_frames=21.23581583409417\n",
      "24000\n",
      "frame=16\n",
      "avg_frames=21.2403649847923\n",
      "25000\n",
      "frame=25\n",
      "avg_frames=21.227110915563376\n",
      "26000\n",
      "frame=27\n",
      "avg_frames=21.220183839083113\n",
      "27000\n",
      "frame=11\n",
      "avg_frames=21.232546942705827\n",
      "28000\n",
      "frame=11\n",
      "avg_frames=21.25352665976215\n",
      "29000\n",
      "frame=23\n",
      "avg_frames=21.27099065549464\n",
      "30000\n",
      "frame=43\n",
      "avg_frames=21.27212426252458\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "LEARNING_RATE = 0.2\n",
    "frame_sum = 0\n",
    "\n",
    "DISCOUNT = 0.95\n",
    "EPISODES = 99000\n",
    "SHOW_EVERY = 1000\n",
    "\n",
    "DISCRETE_OS_SIZE = [10] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high/DISCRETE_OS_SIZE - env.observation_space.low/DISCRETE_OS_SIZE)\n",
    "\n",
    "# Exploration settings\n",
    "epsilon = 1  # not a constant, qoing to be decayed\n",
    "START_EPSILON_DECAYING = 1\n",
    "END_EPSILON_DECAYING = EPISODES*10\n",
    "epsilon_decay_value = epsilon/(END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
    "\n",
    "\n",
    "q_table = np.random.uniform(low=0, high=10, size=(DISCRETE_OS_SIZE + [env.action_space.n]))\n",
    "\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low)/discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int))  # we use this tuple to look up the 3 Q values for the available actions in the q-table\n",
    "\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    discrete_state = get_discrete_state(env.reset())\n",
    "    done = False\n",
    "\n",
    "    if episode % SHOW_EVERY == 0:\n",
    "        render = True\n",
    "        print(episode)\n",
    "    else:\n",
    "        render = False\n",
    "\n",
    "    for frame in range(0,500):\n",
    "\n",
    "        if np.random.random() > epsilon:\n",
    "            # Get action from Q table\n",
    "            action = np.argmax(q_table[discrete_state])\n",
    "        else:\n",
    "            # Get random action\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "\n",
    "\n",
    "        new_state, __, done, _ = env.step(action)\n",
    "\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "\n",
    "        if episode % SHOW_EVERY == 0:\n",
    "            env.render()\n",
    "        #new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "\n",
    "        # If simulation did not end yet after last step - update Q table\n",
    "        if not done:\n",
    "\n",
    "            # Maximum possible Q value in next step (for new state)\n",
    "            max_future_q = np.max(q_table[new_discrete_state])\n",
    "\n",
    "            # Current Q value (for current state and performed action)\n",
    "            current_q = q_table[discrete_state + (action,)]\n",
    "\n",
    "            # And here's our equation for a new Q value for current state and action\n",
    "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * ( DISCOUNT * max_future_q)\n",
    "\n",
    "            # Update Q table with new Q value\n",
    "            q_table[discrete_state + (action,)] = new_q\n",
    "        else:\n",
    "            frame_sum += frame\n",
    "            q_table[discrete_state + (action,)] = frame\n",
    "            if render:\n",
    "                print(f\"frame={frame}\")\n",
    "                print(f\"avg_frames={frame_sum/(episode+1)}\")\n",
    "            break\n",
    "\n",
    "        discrete_state = new_discrete_state\n",
    "\n",
    "    # Decaying is being done every episode if episode number is within decaying range\n",
    "    if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\n",
    "        epsilon -= epsilon_decay_value\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY:\n",
    "    import gym\n",
    "    env = gym.make('CartPole-v1')\n",
    "    score = input(\"Enter the score of the model you want to load \")\n",
    "    model_type = input(\"Enter model type peak_model or avg_model \")\n",
    "    trained_agent = load_model(f\"{SAVE}/{model_type}-{TASK}-{score}.h5\")\n",
    "    state = env.reset()\n",
    "    scores = []\n",
    "    for _ in tqdm(range(PLAY_EPISODES)):\n",
    "        env.reset()\n",
    "        score_per_episode = 0\n",
    "        while True:\n",
    "            action = np.argmax(trained_agent.predict(np.array([state])))\n",
    "            state, reward, done, info = env.step(action)\n",
    "            score_per_episode += reward\n",
    "            if SHOW:\n",
    "                env.render()\n",
    "            if done:\n",
    "                scores.append(score_per_episode)\n",
    "                break\n",
    "        if PLOT:\n",
    "            plot(scores)\n",
    "    print(sum(scores)/PLAY_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
