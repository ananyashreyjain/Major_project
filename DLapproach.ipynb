{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from statistics import mean, median\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "tf.disable_eager_execution()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPoleEnv - Version 0.2.0, Noise case: 1\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "TRIALS = 20\n",
    "params = dict(\n",
    "    goal_steps = 500,\n",
    "    score_requirement = 30,\n",
    "    initial_games = 500,\n",
    "    X = np.array([[]]),\n",
    "    Y = np.array([]),\n",
    "    action = 2,\n",
    "    score = np.array([0]),\n",
    "    plot = False,\n",
    "    model = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(scores=[]):\n",
    "    plt.clf()\n",
    "    avg_scores = [sum(scores[:index+1])/(index+1) for index, \n",
    "                  score in enumerate(scores)]\n",
    "    avg_score = sum(scores)/len(scores)\n",
    "    x_val = [0,len(scores)-1]\n",
    "    y_val = [avg_score, avg_score]\n",
    "    plt.plot(scores,'g-', label='current score')\n",
    "    plt.plot(x_val, y_val,'r-', label='average score')\n",
    "    plt.plot(avg_scores,'b-', label='average scores')\n",
    "    plt.xlabel('Episodes--->')\n",
    "    plt.ylabel('Score--->')\n",
    "    plt.legend()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(params):\n",
    "    env.reset()\n",
    "    for game in range(params[\"initial_games\"]):\n",
    "        env.reset()\n",
    "        game_data = np.array([])\n",
    "        prev_observation = np.array([])\n",
    "        action_list = np.array([])\n",
    "        for step in range(params[\"goal_steps\"]):\n",
    "            if not prev_observation.size or params['model'] is None:\n",
    "                action = env.action_space.sample()\n",
    "            else :\n",
    "                prob_values = model.predict(np.array([prev_observation]))[0]\n",
    "                action = np.argmax(prob_values)\n",
    "            observation, reward, done, info =  env.step(action)\n",
    "            params['score'][-1] += reward\n",
    "            if prev_observation.size :\n",
    "                if not game_data.size:\n",
    "                    game_data = prev_observation\n",
    "                    action_list = np.array([action])\n",
    "                else:\n",
    "                    game_data = np.vstack((game_data, prev_observation))\n",
    "                    action_list = np.concatenate((action_list,action), axis = None)\n",
    "            if done:\n",
    "                break\n",
    "            prev_observation = observation\n",
    "        if params['plot']:\n",
    "            plot(params['score'])\n",
    "        if params['score'][-1] >= params['score_requirement']:\n",
    "            if not params['X'].size:\n",
    "                params['X'] = game_data\n",
    "                params['Y'] = action_list\n",
    "            else:\n",
    "                params['X']=np.concatenate((params['X'], game_data), axis=0)\n",
    "                params['Y']=np.concatenate((params['Y'], action_list))\n",
    "        params['score'] = np.concatenate((params['score'], 0), axis = None)\n",
    "data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 686 samples\n",
      "Epoch 1/10\n",
      "686/686 [==============================] - 0s 674us/sample - loss: 0.6921\n",
      "Epoch 2/10\n",
      "686/686 [==============================] - 0s 56us/sample - loss: 0.6820\n",
      "Epoch 3/10\n",
      "686/686 [==============================] - 0s 71us/sample - loss: 0.6743\n",
      "Epoch 4/10\n",
      "686/686 [==============================] - 0s 61us/sample - loss: 0.6724\n",
      "Epoch 5/10\n",
      "686/686 [==============================] - 0s 74us/sample - loss: 0.6678\n",
      "Epoch 6/10\n",
      "686/686 [==============================] - 0s 73us/sample - loss: 0.6678\n",
      "Epoch 7/10\n",
      "686/686 [==============================] - 0s 55us/sample - loss: 0.6626\n",
      "Epoch 8/10\n",
      "686/686 [==============================] - 0s 70us/sample - loss: 0.6616\n",
      "Epoch 9/10\n",
      "686/686 [==============================] - 0s 62us/sample - loss: 0.6585\n",
      "Epoch 10/10\n",
      "686/686 [==============================] - 0s 52us/sample - loss: 0.6593\n",
      "Train on 7626 samples\n",
      "Epoch 1/10\n",
      "7626/7626 [==============================] - 1s 106us/sample - loss: 0.3013\n",
      "Epoch 2/10\n",
      "7626/7626 [==============================] - 0s 50us/sample - loss: 0.1337\n",
      "Epoch 3/10\n",
      "7626/7626 [==============================] - 0s 51us/sample - loss: 0.1003\n",
      "Epoch 4/10\n",
      "7626/7626 [==============================] - 0s 48us/sample - loss: 0.0811\n",
      "Epoch 5/10\n",
      "7626/7626 [==============================] - 0s 49us/sample - loss: 0.0702\n",
      "Epoch 6/10\n",
      "7626/7626 [==============================] - 0s 51us/sample - loss: 0.0674\n",
      "Epoch 7/10\n",
      "7626/7626 [==============================] - 0s 48us/sample - loss: 0.0578\n",
      "Epoch 8/10\n",
      "7626/7626 [==============================] - 0s 52us/sample - loss: 0.0572\n",
      "Epoch 9/10\n",
      "7626/7626 [==============================] - 0s 50us/sample - loss: 0.0577\n",
      "Epoch 10/10\n",
      "7626/7626 [==============================] - 0s 49us/sample - loss: 0.0491\n",
      "Train on 8638 samples\n",
      "Epoch 1/10\n",
      "8638/8638 [==============================] - 1s 105us/sample - loss: 0.0340\n",
      "Epoch 2/10\n",
      "8638/8638 [==============================] - 0s 51us/sample - loss: 0.0345\n",
      "Epoch 3/10\n",
      "8638/8638 [==============================] - 0s 52us/sample - loss: 0.0321\n",
      "Epoch 4/10\n",
      "8638/8638 [==============================] - 0s 52us/sample - loss: 0.0298\n",
      "Epoch 5/10\n",
      "8638/8638 [==============================] - 0s 52us/sample - loss: 0.0280\n",
      "Epoch 6/10\n",
      "8638/8638 [==============================] - 1s 83us/sample - loss: 0.0293\n",
      "Epoch 7/10\n",
      "8638/8638 [==============================] - 1s 75us/sample - loss: 0.0270\n",
      "Epoch 8/10\n",
      "8638/8638 [==============================] - 0s 51us/sample - loss: 0.0285\n",
      "Epoch 9/10\n",
      "8638/8638 [==============================] - 0s 53us/sample - loss: 0.0276\n",
      "Epoch 10/10\n",
      "8638/8638 [==============================] - 0s 53us/sample - loss: 0.0276\n",
      "Train on 7068 samples\n",
      "Epoch 1/10\n",
      "7068/7068 [==============================] - 1s 118us/sample - loss: 0.0237\n",
      "Epoch 2/10\n",
      "7068/7068 [==============================] - 0s 54us/sample - loss: 0.0248\n",
      "Epoch 3/10\n",
      "7068/7068 [==============================] - 0s 54us/sample - loss: 0.0246\n",
      "Epoch 4/10\n",
      "7068/7068 [==============================] - 0s 52us/sample - loss: 0.0234\n",
      "Epoch 5/10\n",
      "7068/7068 [==============================] - 0s 56us/sample - loss: 0.0236\n",
      "Epoch 6/10\n",
      "7068/7068 [==============================] - 0s 52us/sample - loss: 0.0286\n",
      "Epoch 7/10\n",
      "7068/7068 [==============================] - 0s 53us/sample - loss: 0.0214\n",
      "Epoch 8/10\n",
      "7068/7068 [==============================] - 0s 69us/sample - loss: 0.0185\n",
      "Epoch 9/10\n",
      "7068/7068 [==============================] - 0s 52us/sample - loss: 0.0219\n",
      "Epoch 10/10\n",
      "7068/7068 [==============================] - 0s 51us/sample - loss: 0.0206\n",
      "Train on 5294 samples\n",
      "Epoch 1/10\n",
      "5294/5294 [==============================] - 1s 145us/sample - loss: 0.0224\n",
      "Epoch 2/10\n",
      "5294/5294 [==============================] - 0s 57us/sample - loss: 0.0277\n",
      "Epoch 3/10\n",
      "5294/5294 [==============================] - 0s 58us/sample - loss: 0.0211\n",
      "Epoch 4/10\n",
      "5294/5294 [==============================] - 0s 57us/sample - loss: 0.0217\n",
      "Epoch 5/10\n",
      "5294/5294 [==============================] - 0s 56us/sample - loss: 0.0198\n",
      "Epoch 6/10\n",
      "5294/5294 [==============================] - 0s 56us/sample - loss: 0.0173\n",
      "Epoch 7/10\n",
      "5294/5294 [==============================] - 0s 55us/sample - loss: 0.0207\n",
      "Epoch 8/10\n",
      "5294/5294 [==============================] - 0s 53us/sample - loss: 0.0237\n",
      "Epoch 9/10\n",
      "5294/5294 [==============================] - 0s 52us/sample - loss: 0.0186\n",
      "Epoch 10/10\n",
      "5294/5294 [==============================] - 0s 53us/sample - loss: 0.0177\n",
      "Train on 3416 samples\n",
      "Epoch 1/10\n",
      "3416/3416 [==============================] - 1s 207us/sample - loss: 0.0221\n",
      "Epoch 2/10\n",
      "3416/3416 [==============================] - 0s 53us/sample - loss: 0.0182\n",
      "Epoch 3/10\n",
      "3416/3416 [==============================] - 0s 60us/sample - loss: 0.0195\n",
      "Epoch 4/10\n",
      "3416/3416 [==============================] - 0s 52us/sample - loss: 0.0164\n",
      "Epoch 5/10\n",
      "3416/3416 [==============================] - 0s 84us/sample - loss: 0.0236\n",
      "Epoch 6/10\n",
      "3416/3416 [==============================] - 0s 59us/sample - loss: 0.0176\n",
      "Epoch 7/10\n",
      "3416/3416 [==============================] - 0s 63us/sample - loss: 0.0191\n",
      "Epoch 8/10\n",
      "3416/3416 [==============================] - 0s 55us/sample - loss: 0.0208\n",
      "Epoch 9/10\n",
      "3416/3416 [==============================] - 0s 60us/sample - loss: 0.0157\n",
      "Epoch 10/10\n",
      "3416/3416 [==============================] - 0s 58us/sample - loss: 0.0184\n",
      "Train on 778 samples\n",
      "Epoch 1/10\n",
      "778/778 [==============================] - 1s 735us/sample - loss: 0.0092\n",
      "Epoch 2/10\n",
      "778/778 [==============================] - 0s 63us/sample - loss: 0.0160\n",
      "Epoch 3/10\n",
      "778/778 [==============================] - 0s 62us/sample - loss: 0.0158\n",
      "Epoch 4/10\n",
      "778/778 [==============================] - 0s 58us/sample - loss: 0.0070\n",
      "Epoch 5/10\n",
      "778/778 [==============================] - 0s 58us/sample - loss: 0.0064\n",
      "Epoch 6/10\n",
      "778/778 [==============================] - 0s 60us/sample - loss: 0.0061\n",
      "Epoch 7/10\n",
      "778/778 [==============================] - 0s 80us/sample - loss: 0.0067\n",
      "Epoch 8/10\n",
      "778/778 [==============================] - 0s 115us/sample - loss: 0.0063\n",
      "Epoch 9/10\n",
      "778/778 [==============================] - 0s 69us/sample - loss: 0.0067\n",
      "Epoch 10/10\n",
      "778/778 [==============================] - 0s 60us/sample - loss: 0.0070\n",
      "Train on 179 samples\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/sample - loss: 0.0101\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 126us/sample - loss: 0.0017\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 148us/sample - loss: 0.0013\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 129us/sample - loss: 9.9029e-04\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 191us/sample - loss: 6.7096e-04\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 138us/sample - loss: 6.9136e-04\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 197us/sample - loss: 6.5528e-04\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 153us/sample - loss: 6.0514e-04\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 172us/sample - loss: 5.9675e-04\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 144us/sample - loss: 5.7325e-04\n",
      "Train on 194 samples\n",
      "Epoch 1/10\n",
      "194/194 [==============================] - 1s 4ms/sample - loss: 0.0167\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 0s 153us/sample - loss: 0.0144\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 0s 118us/sample - loss: 0.0081\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 0s 147us/sample - loss: 0.0054\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 0s 129us/sample - loss: 0.0056\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 0s 182us/sample - loss: 0.0034\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 0s 192us/sample - loss: 0.0040\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 0s 179us/sample - loss: 0.0032\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 0s 149us/sample - loss: 0.0033\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 0s 108us/sample - loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(64,input_shape=(4,),activation='relu'),\n",
    "                             tf.keras.layers.Dense(128,activation='relu'),\n",
    "                             tf.keras.layers.Dense(2, activation='softmax'),\n",
    "\n",
    "])\n",
    "final_score_list = params['score']\n",
    "for trial in range(TRIALS):    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    if params['X'].size > 0:\n",
    "        model.fit(params['X'],params['Y'], epochs=10)\n",
    "    else:\n",
    "        break\n",
    "    params = dict(\n",
    "        goal_steps = 500,\n",
    "        score_requirement = 50 + trial * 20,\n",
    "        initial_games = 150,\n",
    "        X = np.array([[]]),\n",
    "        Y = np.array([]),\n",
    "        action = 2,\n",
    "        score = np.array([0]),\n",
    "        plot = False,\n",
    "        model = model\n",
    "    )\n",
    "    data(params)\n",
    "    final_score_list = np.concatenate((final_score_list, params['score']), axis=None)\n",
    "plot(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"DL_model_task2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    goal_steps = 500,\n",
    "    score_requirement = 0,\n",
    "    initial_games = 100,\n",
    "    X = np.array([[]]),\n",
    "    Y = np.array([]),\n",
    "    action = 2,\n",
    "    score = np.array([0]),\n",
    "    plot = True,\n",
    "    model = model\n",
    ")\n",
    "data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
